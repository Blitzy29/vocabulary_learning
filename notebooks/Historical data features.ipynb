{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "def update_working_directory():\n",
    "    from pathlib import Path\n",
    "\n",
    "    p = Path(os.getcwd()).parents[0]\n",
    "    os.chdir(p)\n",
    "    print(p)\n",
    "\n",
    "\n",
    "update_working_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_data(historical_data_path=\"data/raw/historical_data.csv\"):\n",
    "\n",
    "    historical_data = pd.read_csv(historical_data_path)\n",
    "\n",
    "    historical_data[\"day\"] = historical_data[\"datetime\"].apply(\n",
    "        lambda x: datetime.datetime.strftime(\n",
    "            datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\"), \"%Y-%m-%d\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    historical_data[\"day\"] = historical_data[\"day\"].map(\n",
    "        lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\")\n",
    "    )\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = get_historical_data(\"data/raw/historical_data__large.csv\")\n",
    "historical_data[\"id_historical_data\"] = range(len(historical_data))\n",
    "historical_data[\"guess\"].fillna(\"\", inplace=True)\n",
    "historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical dataset\n",
    "from src.data.get_dataset import get_historical_data\n",
    "from src.data.make_historical_features import create_historical_features\n",
    "\n",
    "historical_data = get_historical_data(\"data/raw/historical_data__large.csv\")\n",
    "historical_data = create_historical_features(historical_data)\n",
    "historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occurrences & Days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of previous occurrences/successes/fails before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nb_previous_occurrences(historical_data):\n",
    "\n",
    "    historical_data[\"occurrence\"] = 1\n",
    "\n",
    "    # same language\n",
    "    previous_occurrences = (\n",
    "        historical_data.groupby([\"id_vocab\", \"language_asked\", \"id_historical_data\"])[\n",
    "            \"occurrence\"\n",
    "        ]\n",
    "        .sum()\n",
    "        .groupby(level=[0, 1])\n",
    "        .cumsum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    previous_occurrences.rename(\n",
    "        columns={\"occurrence\": \"previous_occurrences_same_language\"}, inplace=True\n",
    "    )\n",
    "    previous_occurrences[\"previous_occurrences_same_language\"] -= 1\n",
    "\n",
    "    historical_data = pd.merge(\n",
    "        historical_data,\n",
    "        previous_occurrences[\n",
    "            [\"id_historical_data\", \"previous_occurrences_same_language\"]\n",
    "        ],\n",
    "        on=\"id_historical_data\",\n",
    "    )\n",
    "\n",
    "    historical_data[\"previous_successes_same_language\"] = (\n",
    "        historical_data[\"previous_occurrences_same_language\"]\n",
    "        + historical_data[\"score_before\"]\n",
    "    ) / 2\n",
    "    historical_data[\"previous_fails_same_language\"] = (\n",
    "        historical_data[\"previous_occurrences_same_language\"]\n",
    "        - historical_data[\"score_before\"]\n",
    "    ) / 2\n",
    "\n",
    "    # any language\n",
    "    previous_occurrences = (\n",
    "        historical_data.groupby([\"id_vocab\", \"id_historical_data\"])[\"occurrence\"]\n",
    "        .sum()\n",
    "        .groupby(level=0)\n",
    "        .cumsum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    previous_occurrences.rename(\n",
    "        columns={\"occurrence\": \"previous_occurrences_any_language\"}, inplace=True\n",
    "    )\n",
    "    previous_occurrences[\"previous_occurrences_any_language\"] -= 1\n",
    "\n",
    "    historical_data = pd.merge(\n",
    "        historical_data,\n",
    "        previous_occurrences[\n",
    "            [\"id_historical_data\", \"previous_occurrences_any_language\"]\n",
    "        ],\n",
    "        on=\"id_historical_data\",\n",
    "    )\n",
    "\n",
    "    historical_data[\"previous_successes_any_language\"] = (\n",
    "        historical_data[\"previous_occurrences_any_language\"]\n",
    "        + (\n",
    "            historical_data[\"score_before\"]\n",
    "            + historical_data[\"score_before_other_language\"]\n",
    "        )\n",
    "    ) / 2\n",
    "    historical_data[\"previous_fails_any_language\"] = (\n",
    "        historical_data[\"previous_occurrences_any_language\"]\n",
    "        - (\n",
    "            historical_data[\"score_before\"]\n",
    "            + historical_data[\"score_before_other_language\"]\n",
    "        )\n",
    "    ) / 2\n",
    "\n",
    "    del historical_data[\"occurrence\"]\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data.copy()\n",
    "\n",
    "historical_data_test = add_nb_previous_occurrences(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test[historical_data_test[\"german_word\"] == \"die Ã„rztin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_last_occurrence(historical_data):\n",
    "    \n",
    "    # Calculate the difference between rows - By default, periods = 1\n",
    "    historical_data['days_since_last_occurrence_same_language'] = historical_data.groupby(\n",
    "        ['id_vocab','language_asked']\n",
    "    )['day'].diff()\n",
    "\n",
    "    historical_data['days_since_last_occurrence_any_language'] = historical_data.groupby(\n",
    "        'id_vocab'\n",
    "    )['day'].diff()\n",
    "    \n",
    "    historical_data['day_success'] = historical_data['day']\n",
    "    historical_data.loc[historical_data['result'] != 1, 'day_success'] = None\n",
    "    \n",
    "    # Calculate the difference between rows - By default, periods = 1\n",
    "    historical_data['days_since_last_success_same_language'] = historical_data.groupby(\n",
    "        ['id_vocab','language_asked']\n",
    "    )['day_success'].diff()\n",
    "\n",
    "    historical_data['days_since_last_success_any_language'] = historical_data.groupby(\n",
    "        'id_vocab'\n",
    "    )['day_success'].diff()\n",
    "    \n",
    "    del historical_data['day_success']\n",
    "    \n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = add_last_occurrence(historical_data)\n",
    "historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the year'])\n",
    "    | historical_data['german_word'].isin([])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_first_occurrence(historical_data):\n",
    "\n",
    "    day_first_occur_same = historical_data.loc[\n",
    "        historical_data.groupby(\n",
    "            ['id_vocab','language_asked']\n",
    "        )['day'].idxmax()\n",
    "    ]\n",
    "    day_first_occur_same.rename(columns={'day':'day_first_occur_same_language'}, inplace=True)\n",
    "\n",
    "    historical_data = pd.merge(\n",
    "        historical_data,\n",
    "        day_first_occur_same[['id_vocab', 'language_asked', 'day_first_occur_same_language']],\n",
    "        on=['id_vocab', 'language_asked'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    historical_data['days_since_first_occur_same_language'] = (\n",
    "        historical_data['day'] - historical_data['day_first_occur_same_language']\n",
    "    )\n",
    "    \n",
    "    del historical_data['day_first_occur_same_language']\n",
    "    \n",
    "    \n",
    "    day_first_occur_any = historical_data.loc[\n",
    "        historical_data.groupby(\n",
    "            ['id_vocab']\n",
    "        )['day'].idxmax()\n",
    "    ]\n",
    "    day_first_occur_any.rename(columns={'day':'day_first_occur_any_language'}, inplace=True)\n",
    "\n",
    "    historical_data = pd.merge(\n",
    "        historical_data,\n",
    "        day_first_occur_any[['id_vocab', 'day_first_occur_any_language']],\n",
    "        on=['id_vocab'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    historical_data['days_since_first_occur_any_language'] = (\n",
    "        historical_data['day'] - historical_data['day_first_occur_any_language']\n",
    "    )\n",
    "    \n",
    "    del historical_data['day_first_occur_any_language']\n",
    "\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = add_first_occurrence(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error in guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error in article in German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the cup'])\n",
    "    | historical_data['german_word'].isin([])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_german_article(x, list_german_article = ['der','die','das']):\n",
    "    possible_article = x.split(' ', 1)[0]\n",
    "    if possible_article in list_german_article:\n",
    "        return possible_article\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_correct_article(historical_data, list_german_article = ['der','die','das']):\n",
    "    \n",
    "    historical_data['german_word_article'] = None\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        \"german_word_article\"\n",
    "    ] = historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        \"german_word\"\n",
    "    ].map(get_german_article)\n",
    "\n",
    "    historical_data['guess_article'] = None\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        \"guess_article\"\n",
    "    ] = historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        \"guess\"\n",
    "    ].map(get_german_article)\n",
    "    \n",
    "    historical_data['correct_article'] = None\n",
    "    historical_data.loc[\n",
    "        (historical_data['language_asked'] == 'german')\n",
    "        & (historical_data['german_word_article'].isin(list_german_article)),\n",
    "        'correct_article'\n",
    "    ] = historical_data['german_word_article'] == historical_data['guess_article']\n",
    "    \n",
    "    del historical_data['german_word_article']\n",
    "    del historical_data['guess_article']\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = add_correct_article(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levenshtein difference with guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin([])\n",
    "    | historical_data['german_word'].isin(['die Ã„rztin'])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_levenshtein_distance(historical_data):\n",
    "\n",
    "    from Levenshtein import distance\n",
    "    list_german_article = ['der','die','das']\n",
    "    list_english_article = ['the','to']\n",
    "\n",
    "    # Lowercase\n",
    "    historical_data['german_word_lv'] = historical_data['german_word'].str.lower()\n",
    "    historical_data['english_word_lv'] = historical_data['english_word'].str.lower()\n",
    "    historical_data['guess_lv'] = historical_data['guess'].str.lower()\n",
    "\n",
    "    historical_data['german_word_lv'] = historical_data['german_word_lv'].map(\n",
    "        lambda x: ' '.join(word for word in x.split(' ') if word not in list_german_article)\n",
    "    )\n",
    "    historical_data['english_word_lv'] = historical_data['english_word_lv'].map(\n",
    "        lambda x: ' '.join(word for word in x.split(' ') if word not in list_english_article)\n",
    "    )\n",
    "\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        'guess_lv'\n",
    "    ] = historical_data['guess_lv'].map(\n",
    "        lambda x: ' '.join(word for word in x.split(' ') if word not in list_german_article)\n",
    "    )\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'english',\n",
    "        'guess_lv'\n",
    "    ] = historical_data['guess_lv'].map(\n",
    "        lambda x: ' '.join(word for word in x.split(' ') if word not in list_english_article)\n",
    "    )\n",
    "\n",
    "    historical_data['levenshtein_dist'] = None\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        \"levenshtein_dist\"\n",
    "    ] = historical_data.apply(lambda x: distance(x['german_word_lv'], x['guess_lv']), axis=1)\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'english',\n",
    "        \"levenshtein_dist\"\n",
    "    ] = historical_data.apply(lambda x: distance(x['english_word_lv'], x['guess_lv']), axis=1)\n",
    "\n",
    "    del historical_data['german_word_lv']\n",
    "    del historical_data['english_word_lv']\n",
    "    del historical_data['guess_lv']\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = add_levenshtein_distance(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forgotten Uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the year'])\n",
    "    | historical_data['german_word'].isin([])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_only_missed_uppercase(historical_data):\n",
    "\n",
    "    # Lowercase\n",
    "    historical_data['german_word_lv'] = historical_data['german_word'].str.lower()\n",
    "\n",
    "    historical_data['german_word_has_uppercase'] = historical_data['german_word'].map(\n",
    "        lambda x: any(c.isupper() for c in x)\n",
    "    )\n",
    "\n",
    "    historical_data['only_missed_uppercase'] = None\n",
    "\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german','only_missed_uppercase'\n",
    "    ] = (\n",
    "        historical_data['german_word_has_uppercase']\n",
    "        & (historical_data['language_asked'] == 'german')\n",
    "        & (historical_data['german_word_lv'] == historical_data['guess'])\n",
    "    )\n",
    "\n",
    "    del historical_data['german_word_lv']\n",
    "    del historical_data['german_word_has_uppercase']\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = add_only_missed_uppercase(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the year'])\n",
    "    | historical_data['german_word'].isin([])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_previous_results(historical_data):\n",
    "    previous_results = [\n",
    "        'language_asked', 'result', 'question_time'\n",
    "    ]\n",
    "    for i_previous_col in previous_results:\n",
    "        historical_data[f'previous_{i_previous_col}'] = historical_data[i_previous_col]\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = add_previous_results(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many time re-written was perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['really', 'together'])\n",
    "    | historical_data['german_word'].isin([])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data['write_it_again_not_null'] = ~historical_data['write_it_again'].isna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_write_it_again_features(historical_data):\n",
    "    \n",
    "    historical_data['write_it_again_not_null'] = ~historical_data['write_it_again'].isna()\n",
    "    \n",
    "    historical_data.loc[\n",
    "        historical_data['write_it_again_not_null'], 'write_it_again_german'\n",
    "    ] = historical_data.loc[\n",
    "        historical_data['write_it_again_not_null']\n",
    "    ].apply(\n",
    "        lambda row: row['write_it_again'].count(row['german_word']), axis=1\n",
    "    )\n",
    "\n",
    "    historical_data.loc[\n",
    "        historical_data['write_it_again_not_null'], 'write_it_again_english'\n",
    "    ] = historical_data.loc[\n",
    "        historical_data['write_it_again_not_null']\n",
    "    ].apply(\n",
    "        lambda row: row['write_it_again'].count(row['english_word']), axis=1\n",
    "    )\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = add_write_it_again_features(historical_data)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer to datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the year'])\n",
    "    | historical_data['german_word'].isin(['der Pokal','die Ã„rztin'])\n",
    "].copy()\n",
    "historical_data_test = add_nb_previous_occurrences(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_features_to_next_datapoint(historical_data):\n",
    "    \n",
    "    features_to_transfer = [\n",
    "        'correct_article','levenshtein_dist', 'only_missed_uppercase',\n",
    "        'previous_language_asked', 'previous_result', 'previous_question_time',\n",
    "        'write_it_again_not_null', 'write_it_again_german', 'write_it_again_english'\n",
    "    ]\n",
    "    \n",
    "    historical_data = add_correct_article(historical_data)\n",
    "    historical_data = add_levenshtein_distance(historical_data)\n",
    "    historical_data = add_only_missed_uppercase(historical_data)\n",
    "    historical_data = add_previous_results(historical_data)\n",
    "    historical_data = add_write_it_again_features(historical_data)\n",
    "\n",
    "    prev_occur = historical_data[['id_vocab', 'language_asked','previous_occurrences']+features_to_transfer].copy()\n",
    "    prev_occur['new_occurr'] = prev_occur['previous_occurrences'] + 1\n",
    "    del prev_occur['previous_occurrences']\n",
    "\n",
    "    for i_feature_to_transfer in features_to_transfer:\n",
    "        del historical_data[i_feature_to_transfer]\n",
    "\n",
    "    historical_data = pd.merge(\n",
    "        historical_data,\n",
    "        prev_occur,\n",
    "        left_on = ['id_vocab', 'language_asked','previous_occurrences'],\n",
    "        right_on = ['id_vocab', 'language_asked','new_occurr'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = transfer_features_to_next_datapoint(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test[\"week_number\"] = historical_data_test[\"datetime\"].apply(\n",
    "    lambda x: datetime.datetime.strftime(\n",
    "        datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\"), \"%V\"\n",
    "    )\n",
    ")\n",
    "\n",
    "historical_data_test[\"day_week\"] = historical_data_test[\"datetime\"].apply(\n",
    "    lambda x: datetime.datetime.strftime(\n",
    "        datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\"), \"%u\"\n",
    "    )\n",
    ")\n",
    "\n",
    "historical_data_test[\"hour\"] = historical_data_test[\"datetime\"].apply(\n",
    "    lambda x: datetime.datetime.strftime(\n",
    "        datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\"), \"%H\"\n",
    "    )\n",
    ")\n",
    "\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many words during the same day (session?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test_copy = historical_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data_test_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a session\n",
    "\n",
    "historical_data_test[\"datetime_timestamp\"] = historical_data[\"datetime\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    ")\n",
    "\n",
    "historical_data_test[\"time_since_last_question\"] = historical_data_test[\n",
    "    \"datetime_timestamp\"\n",
    "].diff()\n",
    "\n",
    "historical_data_test[\"session_nb\"] = (\n",
    "    historical_data_test[\"time_since_last_question\"] > datetime.timedelta(hours=1)\n",
    ").cumsum()\n",
    "\n",
    "del historical_data_test[\"datetime_timestamp\"]\n",
    "del historical_data_test[\"time_since_last_question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_word_day.rename(columns={\"occurrence\": \"nb_word_day\"}, inplace=True)\n",
    "\n",
    "historical_data_test = pd.merge(\n",
    "    historical_data_test,\n",
    "    nb_word_day[\n",
    "        [\"id_historical_data\", \"nb_word_day\"]\n",
    "    ],\n",
    "    on=\"id_historical_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the year'])\n",
    "    | historical_data['german_word'].isin(['der Pokal','die Ã„rztin'])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = add_nb_previous_occurrences(historical_data_test)\n",
    "historical_data_test = add_last_occurrence(historical_data_test)\n",
    "historical_data_test = add_first_occurrence(historical_data_test)\n",
    "historical_data_test = transfer_features_to_next_datapoint(historical_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "vocabulary_learning",
   "language": "python",
   "name": "vocabulary_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T17:27:30.078111Z",
     "start_time": "2020-10-09T17:27:29.874246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admin/Projects/vocabulary_learning/notebooks\n",
      "/Users/admin/Projects/vocabulary_learning\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\\n\\nimport os\\n\\nprint(os.getcwd())\\n\\n\\ndef update_working_directory():\\n    from pathlib import Path\\n\\n    p = Path(os.getcwd()).parents[0]\\n    os.chdir(p)\\n    print(p)\\n\\n\\nupdate_working_directory()\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\\n\\nimport os\\n\\nprint(os.getcwd())\\n\\n\\ndef update_working_directory():\\n    from pathlib import Path\\n\\n    p = Path(os.getcwd()).parents[0]\\n    os.chdir(p)\\n    print(p)\\n\\n\\nupdate_working_directory()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "def update_working_directory():\n",
    "    from pathlib import Path\n",
    "\n",
    "    p = Path(os.getcwd()).parents[0]\n",
    "    os.chdir(p)\n",
    "    print(p)\n",
    "\n",
    "\n",
    "update_working_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T17:27:34.808879Z",
     "start_time": "2020-10-09T17:27:34.297776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nimport pandas as pd\\n\\n# pd.set_option(\\\"display.max_rows\\\", None)\\npd.set_option(\\\"display.max_columns\\\", None)\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport pandas as pd\\n\\n# pd.set_option(\\\"display.max_rows\\\", None)\\npd.set_option(\\\"display.max_columns\\\", None)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T17:27:35.680717Z",
     "start_time": "2020-10-09T17:27:35.656469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import datetime\";\n",
       "                var nbb_formatted_code = \"import datetime\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T17:27:35.995415Z",
     "start_time": "2020-10-09T17:27:35.954625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def get_historical_data(historical_data_path=\\\"data/raw/historical_data.csv\\\"):\\n\\n    historical_data = pd.read_csv(historical_data_path)\\n\\n    historical_data[\\\"day\\\"] = historical_data[\\\"datetime\\\"].apply(\\n        lambda x: datetime.datetime.strftime(\\n            datetime.datetime.strptime(x, \\\"%Y-%m-%d %H:%M:%S.%f\\\"), \\\"%Y-%m-%d\\\"\\n        )\\n    )\\n\\n    historical_data[\\\"day\\\"] = historical_data[\\\"day\\\"].map(\\n        lambda x: datetime.datetime.strptime(x, \\\"%Y-%m-%d\\\")\\n    )\\n\\n    return historical_data\";\n",
       "                var nbb_formatted_code = \"def get_historical_data(historical_data_path=\\\"data/raw/historical_data.csv\\\"):\\n\\n    historical_data = pd.read_csv(historical_data_path)\\n\\n    historical_data[\\\"day\\\"] = historical_data[\\\"datetime\\\"].apply(\\n        lambda x: datetime.datetime.strftime(\\n            datetime.datetime.strptime(x, \\\"%Y-%m-%d %H:%M:%S.%f\\\"), \\\"%Y-%m-%d\\\"\\n        )\\n    )\\n\\n    historical_data[\\\"day\\\"] = historical_data[\\\"day\\\"].map(\\n        lambda x: datetime.datetime.strptime(x, \\\"%Y-%m-%d\\\")\\n    )\\n\\n    return historical_data\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_historical_data(historical_data_path=\"data/raw/historical_data.csv\"):\n",
    "\n",
    "    historical_data = pd.read_csv(historical_data_path)\n",
    "\n",
    "    historical_data[\"day\"] = historical_data[\"datetime\"].apply(\n",
    "        lambda x: datetime.datetime.strftime(\n",
    "            datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\"), \"%Y-%m-%d\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    historical_data[\"day\"] = historical_data[\"day\"].map(\n",
    "        lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\")\n",
    "    )\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T17:27:37.858589Z",
     "start_time": "2020-10-09T17:27:37.768948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_vocab</th>\n",
       "      <th>german_word</th>\n",
       "      <th>english_word</th>\n",
       "      <th>score_before</th>\n",
       "      <th>score_before_other_language</th>\n",
       "      <th>language_asked</th>\n",
       "      <th>result</th>\n",
       "      <th>guess</th>\n",
       "      <th>question_time</th>\n",
       "      <th>write_it_again</th>\n",
       "      <th>confused_word</th>\n",
       "      <th>is_it_another_word</th>\n",
       "      <th>datetime</th>\n",
       "      <th>day</th>\n",
       "      <th>id_historical_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.0</td>\n",
       "      <td>währen</td>\n",
       "      <td>to last</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>german</td>\n",
       "      <td>0.0</td>\n",
       "      <td>enden</td>\n",
       "      <td>3.0</td>\n",
       "      <td>to last währen währen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-05 22:40:48.990953</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149.0</td>\n",
       "      <td>die Ausbildung</td>\n",
       "      <td>the training</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>english</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the internship</td>\n",
       "      <td>6.0</td>\n",
       "      <td>die Ausbildung the training</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-05 22:40:58.318949</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>die Garantie</td>\n",
       "      <td>the guarantee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>german</td>\n",
       "      <td>0.0</td>\n",
       "      <td>die Guarantee</td>\n",
       "      <td>3.0</td>\n",
       "      <td>the guarantee de Garantie die Grantie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-05 22:41:12.238464</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85.0</td>\n",
       "      <td>der Hahn</td>\n",
       "      <td>the rooster</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>english</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the chicken</td>\n",
       "      <td>9.0</td>\n",
       "      <td>der Hahn the rooster der Hahn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-05 22:41:28.765347</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.0</td>\n",
       "      <td>beachten</td>\n",
       "      <td>to pay attention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>german</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>beachten to pay attention beachten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-05 22:41:44.138936</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>German</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>german</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-08 17:11:12.760509</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>18.0</td>\n",
       "      <td>reservieren</td>\n",
       "      <td>to reserve</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>english</td>\n",
       "      <td>1.0</td>\n",
       "      <td>to reserve</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-08 17:11:15.848705</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>52.0</td>\n",
       "      <td>der Cousin</td>\n",
       "      <td>the cousin</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>english</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the cousin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-08 17:11:19.535079</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>113.0</td>\n",
       "      <td>der Magen</td>\n",
       "      <td>the stomach</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>german</td>\n",
       "      <td>1.0</td>\n",
       "      <td>der Magen</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-08 17:11:23.691143</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>157.0</td>\n",
       "      <td>der Dachboden</td>\n",
       "      <td>the attic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>english</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>der Dachboden the attic der Dachboden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-08 17:11:26.855734</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_vocab     german_word      english_word  score_before  \\\n",
       "0        61.0          währen           to last           0.0   \n",
       "1       149.0  die Ausbildung      the training           0.0   \n",
       "2        46.0    die Garantie     the guarantee           0.0   \n",
       "3        85.0        der Hahn       the rooster           0.0   \n",
       "4        71.0        beachten  to pay attention           0.0   \n",
       "..        ...             ...               ...           ...   \n",
       "315       9.0         Deutsch            German           0.0   \n",
       "316      18.0     reservieren        to reserve           0.0   \n",
       "317      52.0      der Cousin        the cousin           1.0   \n",
       "318     113.0       der Magen       the stomach           0.0   \n",
       "319     157.0   der Dachboden         the attic           0.0   \n",
       "\n",
       "     score_before_other_language language_asked  result           guess  \\\n",
       "0                            0.0         german     0.0           enden   \n",
       "1                            0.0        english     0.0  the internship   \n",
       "2                            0.0         german     0.0   die Guarantee   \n",
       "3                            0.0        english     0.0     the chicken   \n",
       "4                            0.0         german     0.0                   \n",
       "..                           ...            ...     ...             ...   \n",
       "315                          0.0         german     1.0         Deutsch   \n",
       "316                          0.0        english     1.0      to reserve   \n",
       "317                          1.0        english     1.0      the cousin   \n",
       "318                          0.0         german     1.0       der Magen   \n",
       "319                         -1.0        english     0.0                   \n",
       "\n",
       "     question_time                         write_it_again  confused_word  \\\n",
       "0              3.0                  to last währen währen            NaN   \n",
       "1              6.0            die Ausbildung the training            NaN   \n",
       "2              3.0  the guarantee de Garantie die Grantie            NaN   \n",
       "3              9.0          der Hahn the rooster der Hahn            NaN   \n",
       "4              2.0     beachten to pay attention beachten            NaN   \n",
       "..             ...                                    ...            ...   \n",
       "315            3.0                                    NaN            NaN   \n",
       "316            3.0                                    NaN            NaN   \n",
       "317            4.0                                    NaN            NaN   \n",
       "318            3.0                                    NaN            NaN   \n",
       "319            2.0  der Dachboden the attic der Dachboden            NaN   \n",
       "\n",
       "    is_it_another_word                    datetime        day  \\\n",
       "0                  0.0  2020-10-05 22:40:48.990953 2020-10-05   \n",
       "1                  0.0  2020-10-05 22:40:58.318949 2020-10-05   \n",
       "2                  0.0  2020-10-05 22:41:12.238464 2020-10-05   \n",
       "3                  0.0  2020-10-05 22:41:28.765347 2020-10-05   \n",
       "4                  0.0  2020-10-05 22:41:44.138936 2020-10-05   \n",
       "..                 ...                         ...        ...   \n",
       "315                NaN  2020-10-08 17:11:12.760509 2020-10-08   \n",
       "316                NaN  2020-10-08 17:11:15.848705 2020-10-08   \n",
       "317                NaN  2020-10-08 17:11:19.535079 2020-10-08   \n",
       "318                NaN  2020-10-08 17:11:23.691143 2020-10-08   \n",
       "319              False  2020-10-08 17:11:26.855734 2020-10-08   \n",
       "\n",
       "     id_historical_data  \n",
       "0                     0  \n",
       "1                     1  \n",
       "2                     2  \n",
       "3                     3  \n",
       "4                     4  \n",
       "..                  ...  \n",
       "315                 315  \n",
       "316                 316  \n",
       "317                 317  \n",
       "318                 318  \n",
       "319                 319  \n",
       "\n",
       "[320 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"historical_data = get_historical_data(\\\"data/raw/historical_data__large.csv\\\")\\nhistorical_data[\\\"id_historical_data\\\"] = range(len(historical_data))\\nhistorical_data[\\\"guess\\\"].fillna(\\\"\\\", inplace=True)\\nhistorical_data\";\n",
       "                var nbb_formatted_code = \"historical_data = get_historical_data(\\\"data/raw/historical_data__large.csv\\\")\\nhistorical_data[\\\"id_historical_data\\\"] = range(len(historical_data))\\nhistorical_data[\\\"guess\\\"].fillna(\\\"\\\", inplace=True)\\nhistorical_data\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "historical_data = get_historical_data(\"data/raw/historical_data__large.csv\")\n",
    "historical_data[\"id_historical_data\"] = range(len(historical_data))\n",
    "historical_data[\"guess\"].fillna(\"\", inplace=True)\n",
    "historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T17:27:42.317724Z",
     "start_time": "2020-10-09T17:27:41.640564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_vocab</th>\n",
       "      <th>german_word</th>\n",
       "      <th>english_word</th>\n",
       "      <th>score_before</th>\n",
       "      <th>score_before_other_language</th>\n",
       "      <th>language_asked</th>\n",
       "      <th>result</th>\n",
       "      <th>guess</th>\n",
       "      <th>question_time</th>\n",
       "      <th>write_it_again</th>\n",
       "      <th>confused_word</th>\n",
       "      <th>is_it_another_word</th>\n",
       "      <th>datetime</th>\n",
       "      <th>id_session</th>\n",
       "      <th>day</th>\n",
       "      <th>id_historical_data</th>\n",
       "      <th>past_occurrences_same_language</th>\n",
       "      <th>past_successes_same_language</th>\n",
       "      <th>past_fails_same_language</th>\n",
       "      <th>past_occurrences_any_language</th>\n",
       "      <th>past_successes_any_language</th>\n",
       "      <th>past_fails_any_language</th>\n",
       "      <th>days_since_last_occurrence_same_language</th>\n",
       "      <th>days_since_last_occurrence_any_language</th>\n",
       "      <th>days_since_last_success_same_language</th>\n",
       "      <th>days_since_last_success_any_language</th>\n",
       "      <th>previous_score</th>\n",
       "      <th>previous_score_other_language</th>\n",
       "      <th>days_since_first_occur_same_language</th>\n",
       "      <th>days_since_first_occur_any_language</th>\n",
       "      <th>previous_correct_article</th>\n",
       "      <th>previous_levenshtein_distance_guess_answer</th>\n",
       "      <th>previous_only_missed_uppercase</th>\n",
       "      <th>previous_language_asked</th>\n",
       "      <th>previous_result</th>\n",
       "      <th>previous_question_time</th>\n",
       "      <th>previous_write_it_again_not_null</th>\n",
       "      <th>previous_write_it_again_german</th>\n",
       "      <th>previous_write_it_again_english</th>\n",
       "      <th>previous_confused_with_another_word</th>\n",
       "      <th>previous_confused_with_an_unknown_word</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>nb_words_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.0</td>\n",
       "      <td>währen</td>\n",
       "      <td>to last</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>german</td>\n",
       "      <td>0.0</td>\n",
       "      <td>enden</td>\n",
       "      <td>3.0</td>\n",
       "      <td>to last währen währen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-05 22:40:48.990953</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149.0</td>\n",
       "      <td>die Ausbildung</td>\n",
       "      <td>the training</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>english</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the internship</td>\n",
       "      <td>6.0</td>\n",
       "      <td>die Ausbildung the training</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-05 22:40:58.318949</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>die Garantie</td>\n",
       "      <td>the guarantee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>german</td>\n",
       "      <td>0.0</td>\n",
       "      <td>die Guarantee</td>\n",
       "      <td>3.0</td>\n",
       "      <td>the guarantee de Garantie die Grantie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-05 22:41:12.238464</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85.0</td>\n",
       "      <td>der Hahn</td>\n",
       "      <td>the rooster</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>english</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the chicken</td>\n",
       "      <td>9.0</td>\n",
       "      <td>der Hahn the rooster der Hahn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-05 22:41:28.765347</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.0</td>\n",
       "      <td>beachten</td>\n",
       "      <td>to pay attention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>german</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>beachten to pay attention beachten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-05 22:41:44.138936</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>German</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>german</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-08 17:11:12.760509</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1 days</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>18.0</td>\n",
       "      <td>reservieren</td>\n",
       "      <td>to reserve</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>english</td>\n",
       "      <td>1.0</td>\n",
       "      <td>to reserve</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-08 17:11:15.848705</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>52.0</td>\n",
       "      <td>der Cousin</td>\n",
       "      <td>the cousin</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>english</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the cousin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-08 17:11:19.535079</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1 days</td>\n",
       "      <td>-1 days</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>english</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>113.0</td>\n",
       "      <td>der Magen</td>\n",
       "      <td>the stomach</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>german</td>\n",
       "      <td>1.0</td>\n",
       "      <td>der Magen</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-08 17:11:23.691143</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>318</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1 days</td>\n",
       "      <td>-1 days</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>german</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>157.0</td>\n",
       "      <td>der Dachboden</td>\n",
       "      <td>the attic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>english</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>der Dachboden the attic der Dachboden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-10-08 17:11:26.855734</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2 days</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_vocab     german_word      english_word  score_before  \\\n",
       "0        61.0          währen           to last           0.0   \n",
       "1       149.0  die Ausbildung      the training           0.0   \n",
       "2        46.0    die Garantie     the guarantee           0.0   \n",
       "3        85.0        der Hahn       the rooster           0.0   \n",
       "4        71.0        beachten  to pay attention           0.0   \n",
       "..        ...             ...               ...           ...   \n",
       "315       9.0         Deutsch            German           0.0   \n",
       "316      18.0     reservieren        to reserve           0.0   \n",
       "317      52.0      der Cousin        the cousin           1.0   \n",
       "318     113.0       der Magen       the stomach           0.0   \n",
       "319     157.0   der Dachboden         the attic           0.0   \n",
       "\n",
       "     score_before_other_language language_asked  result           guess  \\\n",
       "0                            0.0         german     0.0           enden   \n",
       "1                            0.0        english     0.0  the internship   \n",
       "2                            0.0         german     0.0   die Guarantee   \n",
       "3                            0.0        english     0.0     the chicken   \n",
       "4                            0.0         german     0.0                   \n",
       "..                           ...            ...     ...             ...   \n",
       "315                          0.0         german     1.0         Deutsch   \n",
       "316                          0.0        english     1.0      to reserve   \n",
       "317                          1.0        english     1.0      the cousin   \n",
       "318                          0.0         german     1.0       der Magen   \n",
       "319                         -1.0        english     0.0                   \n",
       "\n",
       "     question_time                         write_it_again  confused_word  \\\n",
       "0              3.0                  to last währen währen            NaN   \n",
       "1              6.0            die Ausbildung the training            NaN   \n",
       "2              3.0  the guarantee de Garantie die Grantie            NaN   \n",
       "3              9.0          der Hahn the rooster der Hahn            NaN   \n",
       "4              2.0     beachten to pay attention beachten            NaN   \n",
       "..             ...                                    ...            ...   \n",
       "315            3.0                                    NaN            NaN   \n",
       "316            3.0                                    NaN            NaN   \n",
       "317            4.0                                    NaN            NaN   \n",
       "318            3.0                                    NaN            NaN   \n",
       "319            2.0  der Dachboden the attic der Dachboden            NaN   \n",
       "\n",
       "    is_it_another_word                    datetime  id_session        day  \\\n",
       "0                  0.0  2020-10-05 22:40:48.990953           0 2020-10-05   \n",
       "1                  0.0  2020-10-05 22:40:58.318949           0 2020-10-05   \n",
       "2                  0.0  2020-10-05 22:41:12.238464           0 2020-10-05   \n",
       "3                  0.0  2020-10-05 22:41:28.765347           0 2020-10-05   \n",
       "4                  0.0  2020-10-05 22:41:44.138936           0 2020-10-05   \n",
       "..                 ...                         ...         ...        ...   \n",
       "315                NaN  2020-10-08 17:11:12.760509           5 2020-10-08   \n",
       "316                NaN  2020-10-08 17:11:15.848705           5 2020-10-08   \n",
       "317                NaN  2020-10-08 17:11:19.535079           5 2020-10-08   \n",
       "318                NaN  2020-10-08 17:11:23.691143           5 2020-10-08   \n",
       "319              False  2020-10-08 17:11:26.855734           5 2020-10-08   \n",
       "\n",
       "     id_historical_data  past_occurrences_same_language  \\\n",
       "0                     0                               0   \n",
       "1                     1                               0   \n",
       "2                     2                               0   \n",
       "3                     3                               0   \n",
       "4                     4                               0   \n",
       "..                  ...                             ...   \n",
       "315                 315                               0   \n",
       "316                 316                               0   \n",
       "317                 317                               1   \n",
       "318                 318                               2   \n",
       "319                 319                               0   \n",
       "\n",
       "     past_successes_same_language  past_fails_same_language  \\\n",
       "0                             0.0                       0.0   \n",
       "1                             0.0                       0.0   \n",
       "2                             0.0                       0.0   \n",
       "3                             0.0                       0.0   \n",
       "4                             0.0                       0.0   \n",
       "..                            ...                       ...   \n",
       "315                           0.0                       0.0   \n",
       "316                           0.0                       0.0   \n",
       "317                           1.0                       0.0   \n",
       "318                           1.0                       1.0   \n",
       "319                           0.0                       0.0   \n",
       "\n",
       "     past_occurrences_any_language  past_successes_any_language  \\\n",
       "0                                0                          0.0   \n",
       "1                                0                          0.0   \n",
       "2                                0                          0.0   \n",
       "3                                0                          0.0   \n",
       "4                                0                          0.0   \n",
       "..                             ...                          ...   \n",
       "315                              2                          1.0   \n",
       "316                              0                          0.0   \n",
       "317                              2                          2.0   \n",
       "318                              2                          1.0   \n",
       "319                              1                          0.0   \n",
       "\n",
       "     past_fails_any_language days_since_last_occurrence_same_language  \\\n",
       "0                        0.0                                      NaT   \n",
       "1                        0.0                                      NaT   \n",
       "2                        0.0                                      NaT   \n",
       "3                        0.0                                      NaT   \n",
       "4                        0.0                                      NaT   \n",
       "..                       ...                                      ...   \n",
       "315                      1.0                                      NaT   \n",
       "316                      0.0                                      NaT   \n",
       "317                      0.0                                   1 days   \n",
       "318                      1.0                                   1 days   \n",
       "319                      1.0                                      NaT   \n",
       "\n",
       "    days_since_last_occurrence_any_language  \\\n",
       "0                                       NaT   \n",
       "1                                       NaT   \n",
       "2                                       NaT   \n",
       "3                                       NaT   \n",
       "4                                       NaT   \n",
       "..                                      ...   \n",
       "315                                  1 days   \n",
       "316                                     NaT   \n",
       "317                                  1 days   \n",
       "318                                  1 days   \n",
       "319                                  2 days   \n",
       "\n",
       "    days_since_last_success_same_language  \\\n",
       "0                                     NaT   \n",
       "1                                     NaT   \n",
       "2                                     NaT   \n",
       "3                                     NaT   \n",
       "4                                     NaT   \n",
       "..                                    ...   \n",
       "315                                   NaT   \n",
       "316                                   NaT   \n",
       "317                                1 days   \n",
       "318                                1 days   \n",
       "319                                   NaT   \n",
       "\n",
       "    days_since_last_success_any_language  previous_score  \\\n",
       "0                                    NaT             0.0   \n",
       "1                                    NaT             0.0   \n",
       "2                                    NaT             0.0   \n",
       "3                                    NaT             0.0   \n",
       "4                                    NaT             0.0   \n",
       "..                                   ...             ...   \n",
       "315                               1 days             0.0   \n",
       "316                                  NaT             0.0   \n",
       "317                               1 days             1.0   \n",
       "318                               1 days             0.0   \n",
       "319                                  NaT             0.0   \n",
       "\n",
       "     previous_score_other_language days_since_first_occur_same_language  \\\n",
       "0                              0.0                                  NaT   \n",
       "1                              0.0                                  NaT   \n",
       "2                              0.0                                  NaT   \n",
       "3                              0.0                                  NaT   \n",
       "4                              0.0                                  NaT   \n",
       "..                             ...                                  ...   \n",
       "315                            0.0                                  NaT   \n",
       "316                            0.0                                  NaT   \n",
       "317                            1.0                              -1 days   \n",
       "318                            0.0                              -1 days   \n",
       "319                           -1.0                                  NaT   \n",
       "\n",
       "    days_since_first_occur_any_language previous_correct_article  \\\n",
       "0                                   NaT                      NaN   \n",
       "1                                   NaT                      NaN   \n",
       "2                                   NaT                      NaN   \n",
       "3                                   NaT                      NaN   \n",
       "4                                   NaT                      NaN   \n",
       "..                                  ...                      ...   \n",
       "315                                 NaT                      NaN   \n",
       "316                                 NaT                      NaN   \n",
       "317                             -1 days                     None   \n",
       "318                             -1 days                     True   \n",
       "319                                 NaT                      NaN   \n",
       "\n",
       "    previous_levenshtein_distance_guess_answer previous_only_missed_uppercase  \\\n",
       "0                                          NaN                            NaN   \n",
       "1                                          NaN                            NaN   \n",
       "2                                          NaN                            NaN   \n",
       "3                                          NaN                            NaN   \n",
       "4                                          NaN                            NaN   \n",
       "..                                         ...                            ...   \n",
       "315                                        NaN                            NaN   \n",
       "316                                        NaN                            NaN   \n",
       "317                                          0                           None   \n",
       "318                                          0                          False   \n",
       "319                                        NaN                            NaN   \n",
       "\n",
       "    previous_language_asked  previous_result  previous_question_time  \\\n",
       "0                       NaN              NaN                     NaN   \n",
       "1                       NaN              NaN                     NaN   \n",
       "2                       NaN              NaN                     NaN   \n",
       "3                       NaN              NaN                     NaN   \n",
       "4                       NaN              NaN                     NaN   \n",
       "..                      ...              ...                     ...   \n",
       "315                     NaN              NaN                     NaN   \n",
       "316                     NaN              NaN                     NaN   \n",
       "317                 english              1.0                     3.0   \n",
       "318                  german              1.0                     3.0   \n",
       "319                     NaN              NaN                     NaN   \n",
       "\n",
       "    previous_write_it_again_not_null  previous_write_it_again_german  \\\n",
       "0                                NaN                             NaN   \n",
       "1                                NaN                             NaN   \n",
       "2                                NaN                             NaN   \n",
       "3                                NaN                             NaN   \n",
       "4                                NaN                             NaN   \n",
       "..                               ...                             ...   \n",
       "315                              NaN                             NaN   \n",
       "316                              NaN                             NaN   \n",
       "317                            False                             NaN   \n",
       "318                            False                             NaN   \n",
       "319                              NaN                             NaN   \n",
       "\n",
       "     previous_write_it_again_english previous_confused_with_another_word  \\\n",
       "0                                NaN                                 NaN   \n",
       "1                                NaN                                 NaN   \n",
       "2                                NaN                                 NaN   \n",
       "3                                NaN                                 NaN   \n",
       "4                                NaN                                 NaN   \n",
       "..                               ...                                 ...   \n",
       "315                              NaN                                 NaN   \n",
       "316                              NaN                                 NaN   \n",
       "317                              NaN                               False   \n",
       "318                              NaN                               False   \n",
       "319                              NaN                                 NaN   \n",
       "\n",
       "    previous_confused_with_an_unknown_word week_number day_week hour  \\\n",
       "0                                      NaN          41        1   22   \n",
       "1                                      NaN          41        1   22   \n",
       "2                                      NaN          41        1   22   \n",
       "3                                      NaN          41        1   22   \n",
       "4                                      NaN          41        1   22   \n",
       "..                                     ...         ...      ...  ...   \n",
       "315                                    NaN          41        4   17   \n",
       "316                                    NaN          41        4   17   \n",
       "317                                    NaN          41        4   17   \n",
       "318                                    NaN          41        4   17   \n",
       "319                                    NaN          41        4   17   \n",
       "\n",
       "     nb_words_session  \n",
       "0                   1  \n",
       "1                   2  \n",
       "2                   3  \n",
       "3                   4  \n",
       "4                   5  \n",
       "..                ...  \n",
       "315                96  \n",
       "316                97  \n",
       "317                98  \n",
       "318                99  \n",
       "319               100  \n",
       "\n",
       "[320 rows x 45 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# Historical dataset\\nfrom src.data.get_dataset import get_historical_data\\nfrom src.data.make_historical_features import create_historical_features\\n\\nhistorical_data = get_historical_data(\\\"data/raw/historical_data__large.csv\\\")\\nhistorical_data = create_historical_features(historical_data)\\nhistorical_data\";\n",
       "                var nbb_formatted_code = \"# Historical dataset\\nfrom src.data.get_dataset import get_historical_data\\nfrom src.data.make_historical_features import create_historical_features\\n\\nhistorical_data = get_historical_data(\\\"data/raw/historical_data__large.csv\\\")\\nhistorical_data = create_historical_features(historical_data)\\nhistorical_data\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Historical dataset\n",
    "from src.data.get_dataset import get_historical_data\n",
    "from src.data.make_historical_features import create_historical_features\n",
    "\n",
    "historical_data = get_historical_data(\"data/raw/historical_data__large.csv\")\n",
    "historical_data = create_historical_features(historical_data)\n",
    "historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occurrences & Days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of previous occurrences/successes/fails before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nb_previous_occurrences(historical_data):\n",
    "\n",
    "    historical_data[\"occurrence\"] = 1\n",
    "\n",
    "    # same language\n",
    "    previous_occurrences = (\n",
    "        historical_data.groupby([\"id_vocab\", \"language_asked\", \"id_historical_data\"])[\n",
    "            \"occurrence\"\n",
    "        ]\n",
    "        .sum()\n",
    "        .groupby(level=[0, 1])\n",
    "        .cumsum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    previous_occurrences.rename(\n",
    "        columns={\"occurrence\": \"previous_occurrences_same_language\"}, inplace=True\n",
    "    )\n",
    "    previous_occurrences[\"previous_occurrences_same_language\"] -= 1\n",
    "\n",
    "    historical_data = pd.merge(\n",
    "        historical_data,\n",
    "        previous_occurrences[\n",
    "            [\"id_historical_data\", \"previous_occurrences_same_language\"]\n",
    "        ],\n",
    "        on=\"id_historical_data\",\n",
    "    )\n",
    "\n",
    "    historical_data[\"previous_successes_same_language\"] = (\n",
    "        historical_data[\"previous_occurrences_same_language\"]\n",
    "        + historical_data[\"score_before\"]\n",
    "    ) / 2\n",
    "    historical_data[\"previous_fails_same_language\"] = (\n",
    "        historical_data[\"previous_occurrences_same_language\"]\n",
    "        - historical_data[\"score_before\"]\n",
    "    ) / 2\n",
    "\n",
    "    # any language\n",
    "    previous_occurrences = (\n",
    "        historical_data.groupby([\"id_vocab\", \"id_historical_data\"])[\"occurrence\"]\n",
    "        .sum()\n",
    "        .groupby(level=0)\n",
    "        .cumsum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    previous_occurrences.rename(\n",
    "        columns={\"occurrence\": \"previous_occurrences_any_language\"}, inplace=True\n",
    "    )\n",
    "    previous_occurrences[\"previous_occurrences_any_language\"] -= 1\n",
    "\n",
    "    historical_data = pd.merge(\n",
    "        historical_data,\n",
    "        previous_occurrences[\n",
    "            [\"id_historical_data\", \"previous_occurrences_any_language\"]\n",
    "        ],\n",
    "        on=\"id_historical_data\",\n",
    "    )\n",
    "\n",
    "    historical_data[\"previous_successes_any_language\"] = (\n",
    "        historical_data[\"previous_occurrences_any_language\"]\n",
    "        + (\n",
    "            historical_data[\"score_before\"]\n",
    "            + historical_data[\"score_before_other_language\"]\n",
    "        )\n",
    "    ) / 2\n",
    "    historical_data[\"previous_fails_any_language\"] = (\n",
    "        historical_data[\"previous_occurrences_any_language\"]\n",
    "        - (\n",
    "            historical_data[\"score_before\"]\n",
    "            + historical_data[\"score_before_other_language\"]\n",
    "        )\n",
    "    ) / 2\n",
    "\n",
    "    del historical_data[\"occurrence\"]\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data.copy()\n",
    "\n",
    "historical_data_test = add_nb_previous_occurrences(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test[historical_data_test[\"german_word\"] == \"die Ärztin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Last occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = historical_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def add_last_occurrence(historical_data):\n",
    "    \n",
    "    # Calculate the difference between rows - By default, periods = 1\n",
    "    historical_data['days_since_last_occurrence_same_language'] = historical_data.groupby(\n",
    "        ['id_vocab','language_asked']\n",
    "    )['day'].diff()\n",
    "\n",
    "    historical_data['days_since_last_occurrence_any_language'] = historical_data.groupby(\n",
    "        'id_vocab'\n",
    "    )['day'].diff()\n",
    "    \n",
    "    historical_data['day_success'] = historical_data['day']\n",
    "    historical_data.loc[historical_data['result'] != 1, 'day_success'] = None\n",
    "    \n",
    "    # Calculate the difference between rows - By default, periods = 1\n",
    "    historical_data['days_since_last_success_same_language'] = historical_data.groupby(\n",
    "        ['id_vocab','language_asked']\n",
    "    )['day_success'].diff()\n",
    "\n",
    "    historical_data['days_since_last_success_any_language'] = historical_data.groupby(\n",
    "        'id_vocab'\n",
    "    )['day_success'].diff()\n",
    "    \n",
    "    del historical_data['day_success']\n",
    "    \n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data = add_last_occurrence(historical_data)\n",
    "historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## First occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the year'])\n",
    "    | historical_data['german_word'].isin([])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def add_first_occurrence(historical_data):\n",
    "\n",
    "    day_first_occur_same = historical_data.loc[\n",
    "        historical_data.groupby(\n",
    "            ['id_vocab','language_asked']\n",
    "        )['day'].idxmax()\n",
    "    ]\n",
    "    day_first_occur_same.rename(columns={'day':'day_first_occur_same_language'}, inplace=True)\n",
    "\n",
    "    historical_data = pd.merge(\n",
    "        historical_data,\n",
    "        day_first_occur_same[['id_vocab', 'language_asked', 'day_first_occur_same_language']],\n",
    "        on=['id_vocab', 'language_asked'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    historical_data['days_since_first_occur_same_language'] = (\n",
    "        historical_data['day'] - historical_data['day_first_occur_same_language']\n",
    "    )\n",
    "    \n",
    "    del historical_data['day_first_occur_same_language']\n",
    "    \n",
    "    \n",
    "    day_first_occur_any = historical_data.loc[\n",
    "        historical_data.groupby(\n",
    "            ['id_vocab']\n",
    "        )['day'].idxmax()\n",
    "    ]\n",
    "    day_first_occur_any.rename(columns={'day':'day_first_occur_any_language'}, inplace=True)\n",
    "\n",
    "    historical_data = pd.merge(\n",
    "        historical_data,\n",
    "        day_first_occur_any[['id_vocab', 'day_first_occur_any_language']],\n",
    "        on=['id_vocab'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    historical_data['days_since_first_occur_any_language'] = (\n",
    "        historical_data['day'] - historical_data['day_first_occur_any_language']\n",
    "    )\n",
    "    \n",
    "    del historical_data['day_first_occur_any_language']\n",
    "\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = add_first_occurrence(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error in guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Error in article in German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the cup'])\n",
    "    | historical_data['german_word'].isin([])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_german_article(x, list_german_article = ['der','die','das']):\n",
    "    possible_article = x.split(' ', 1)[0]\n",
    "    if possible_article in list_german_article:\n",
    "        return possible_article\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def add_correct_article(historical_data, list_german_article = ['der','die','das']):\n",
    "    \n",
    "    historical_data['german_word_article'] = None\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        \"german_word_article\"\n",
    "    ] = historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        \"german_word\"\n",
    "    ].map(get_german_article)\n",
    "\n",
    "    historical_data['guess_article'] = None\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        \"guess_article\"\n",
    "    ] = historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        \"guess\"\n",
    "    ].map(get_german_article)\n",
    "    \n",
    "    historical_data['correct_article'] = None\n",
    "    historical_data.loc[\n",
    "        (historical_data['language_asked'] == 'german')\n",
    "        & (historical_data['german_word_article'].isin(list_german_article)),\n",
    "        'correct_article'\n",
    "    ] = historical_data['german_word_article'] == historical_data['guess_article']\n",
    "    \n",
    "    del historical_data['german_word_article']\n",
    "    del historical_data['guess_article']\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = add_correct_article(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Levenshtein difference with guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin([])\n",
    "    | historical_data['german_word'].isin(['die Ärztin'])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def add_levenshtein_distance(historical_data):\n",
    "\n",
    "    from Levenshtein import distance\n",
    "    list_german_article = ['der','die','das']\n",
    "    list_english_article = ['the','to']\n",
    "\n",
    "    # Lowercase\n",
    "    historical_data['german_word_lv'] = historical_data['german_word'].str.lower()\n",
    "    historical_data['english_word_lv'] = historical_data['english_word'].str.lower()\n",
    "    historical_data['guess_lv'] = historical_data['guess'].str.lower()\n",
    "\n",
    "    historical_data['german_word_lv'] = historical_data['german_word_lv'].map(\n",
    "        lambda x: ' '.join(word for word in x.split(' ') if word not in list_german_article)\n",
    "    )\n",
    "    historical_data['english_word_lv'] = historical_data['english_word_lv'].map(\n",
    "        lambda x: ' '.join(word for word in x.split(' ') if word not in list_english_article)\n",
    "    )\n",
    "\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        'guess_lv'\n",
    "    ] = historical_data['guess_lv'].map(\n",
    "        lambda x: ' '.join(word for word in x.split(' ') if word not in list_german_article)\n",
    "    )\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'english',\n",
    "        'guess_lv'\n",
    "    ] = historical_data['guess_lv'].map(\n",
    "        lambda x: ' '.join(word for word in x.split(' ') if word not in list_english_article)\n",
    "    )\n",
    "\n",
    "    historical_data['levenshtein_dist'] = None\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german',\n",
    "        \"levenshtein_dist\"\n",
    "    ] = historical_data.apply(lambda x: distance(x['german_word_lv'], x['guess_lv']), axis=1)\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'english',\n",
    "        \"levenshtein_dist\"\n",
    "    ] = historical_data.apply(lambda x: distance(x['english_word_lv'], x['guess_lv']), axis=1)\n",
    "\n",
    "    del historical_data['german_word_lv']\n",
    "    del historical_data['english_word_lv']\n",
    "    del historical_data['guess_lv']\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = add_levenshtein_distance(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Forgotten Uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the year'])\n",
    "    | historical_data['german_word'].isin([])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def add_only_missed_uppercase(historical_data):\n",
    "\n",
    "    # Lowercase\n",
    "    historical_data['german_word_lv'] = historical_data['german_word'].str.lower()\n",
    "\n",
    "    historical_data['german_word_has_uppercase'] = historical_data['german_word'].map(\n",
    "        lambda x: any(c.isupper() for c in x)\n",
    "    )\n",
    "\n",
    "    historical_data['only_missed_uppercase'] = None\n",
    "\n",
    "    historical_data.loc[\n",
    "        historical_data['language_asked'] == 'german','only_missed_uppercase'\n",
    "    ] = (\n",
    "        historical_data['german_word_has_uppercase']\n",
    "        & (historical_data['language_asked'] == 'german')\n",
    "        & (historical_data['german_word_lv'] == historical_data['guess'])\n",
    "    )\n",
    "\n",
    "    del historical_data['german_word_lv']\n",
    "    del historical_data['german_word_has_uppercase']\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = add_only_missed_uppercase(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the year'])\n",
    "    | historical_data['german_word'].isin([])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def add_previous_results(historical_data):\n",
    "    previous_results = [\n",
    "        'language_asked', 'result', 'question_time'\n",
    "    ]\n",
    "    for i_previous_col in previous_results:\n",
    "        historical_data[f'previous_{i_previous_col}'] = historical_data[i_previous_col]\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = add_previous_results(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How many time re-written was perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['really', 'together'])\n",
    "    | historical_data['german_word'].isin([])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data['write_it_again_not_null'] = ~historical_data['write_it_again'].isna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def add_write_it_again_features(historical_data):\n",
    "    \n",
    "    historical_data['write_it_again_not_null'] = ~historical_data['write_it_again'].isna()\n",
    "    \n",
    "    historical_data.loc[\n",
    "        historical_data['write_it_again_not_null'], 'write_it_again_german'\n",
    "    ] = historical_data.loc[\n",
    "        historical_data['write_it_again_not_null']\n",
    "    ].apply(\n",
    "        lambda row: row['write_it_again'].count(row['german_word']), axis=1\n",
    "    )\n",
    "\n",
    "    historical_data.loc[\n",
    "        historical_data['write_it_again_not_null'], 'write_it_again_english'\n",
    "    ] = historical_data.loc[\n",
    "        historical_data['write_it_again_not_null']\n",
    "    ].apply(\n",
    "        lambda row: row['write_it_again'].count(row['english_word']), axis=1\n",
    "    )\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "historical_data_test = add_write_it_again_features(historical_data)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confused with another word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T17:23:02.259398Z",
     "start_time": "2020-10-09T17:23:02.206356Z"
    }
   },
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data[\"english_word\"].isin([\"really\", \"together\"])\n",
    "    | historical_data[\"german_word\"].isin([\"wieder\", \"oft\"])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T17:23:03.431778Z",
     "start_time": "2020-10-09T17:23:03.382550Z"
    }
   },
   "outputs": [],
   "source": [
    "add_confused_features(historical_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer to datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the year'])\n",
    "    | historical_data['german_word'].isin(['der Pokal','die Ärztin'])\n",
    "].copy()\n",
    "historical_data_test = add_nb_previous_occurrences(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_features_to_next_datapoint(historical_data):\n",
    "    \n",
    "    features_to_transfer = [\n",
    "        'correct_article','levenshtein_dist', 'only_missed_uppercase',\n",
    "        'previous_language_asked', 'previous_result', 'previous_question_time',\n",
    "        'write_it_again_not_null', 'write_it_again_german', 'write_it_again_english'\n",
    "    ]\n",
    "    \n",
    "    historical_data = add_correct_article(historical_data)\n",
    "    historical_data = add_levenshtein_distance(historical_data)\n",
    "    historical_data = add_only_missed_uppercase(historical_data)\n",
    "    historical_data = add_previous_results(historical_data)\n",
    "    historical_data = add_write_it_again_features(historical_data)\n",
    "\n",
    "    prev_occur = historical_data[['id_vocab', 'language_asked','previous_occurrences']+features_to_transfer].copy()\n",
    "    prev_occur['new_occurr'] = prev_occur['previous_occurrences'] + 1\n",
    "    del prev_occur['previous_occurrences']\n",
    "\n",
    "    for i_feature_to_transfer in features_to_transfer:\n",
    "        del historical_data[i_feature_to_transfer]\n",
    "\n",
    "    historical_data = pd.merge(\n",
    "        historical_data,\n",
    "        prev_occur,\n",
    "        left_on = ['id_vocab', 'language_asked','previous_occurrences'],\n",
    "        right_on = ['id_vocab', 'language_asked','new_occurr'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = transfer_features_to_next_datapoint(historical_data_test)\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test[\"week_number\"] = historical_data_test[\"datetime\"].apply(\n",
    "    lambda x: datetime.datetime.strftime(\n",
    "        datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\"), \"%V\"\n",
    "    )\n",
    ")\n",
    "\n",
    "historical_data_test[\"day_week\"] = historical_data_test[\"datetime\"].apply(\n",
    "    lambda x: datetime.datetime.strftime(\n",
    "        datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\"), \"%u\"\n",
    "    )\n",
    ")\n",
    "\n",
    "historical_data_test[\"hour\"] = historical_data_test[\"datetime\"].apply(\n",
    "    lambda x: datetime.datetime.strftime(\n",
    "        datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\"), \"%H\"\n",
    "    )\n",
    ")\n",
    "\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many words during the same day (session?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test_copy = historical_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data_test_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a session\n",
    "\n",
    "historical_data_test[\"datetime_timestamp\"] = historical_data[\"datetime\"].apply(\n",
    "    lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    ")\n",
    "\n",
    "historical_data_test[\"time_since_last_question\"] = historical_data_test[\n",
    "    \"datetime_timestamp\"\n",
    "].diff()\n",
    "\n",
    "historical_data_test[\"session_nb\"] = (\n",
    "    historical_data_test[\"time_since_last_question\"] > datetime.timedelta(hours=1)\n",
    ").cumsum()\n",
    "\n",
    "del historical_data_test[\"datetime_timestamp\"]\n",
    "del historical_data_test[\"time_since_last_question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_word_day.rename(columns={\"occurrence\": \"nb_word_day\"}, inplace=True)\n",
    "\n",
    "historical_data_test = pd.merge(\n",
    "    historical_data_test,\n",
    "    nb_word_day[\n",
    "        [\"id_historical_data\", \"nb_word_day\"]\n",
    "    ],\n",
    "    on=\"id_historical_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = historical_data[\n",
    "    historical_data['english_word'].isin(['the year'])\n",
    "    | historical_data['german_word'].isin(['der Pokal','die Ärztin'])\n",
    "].copy()\n",
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test = add_nb_previous_occurrences(historical_data_test)\n",
    "historical_data_test = add_last_occurrence(historical_data_test)\n",
    "historical_data_test = add_first_occurrence(historical_data_test)\n",
    "historical_data_test = transfer_features_to_next_datapoint(historical_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "vocabulary_learning",
   "language": "python",
   "name": "vocabulary_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

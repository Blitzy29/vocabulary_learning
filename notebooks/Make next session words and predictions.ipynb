{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "def update_working_directory():\n",
    "    from pathlib import Path\n",
    "\n",
    "    p = Path(os.getcwd()).parents[0]\n",
    "    os.chdir(p)\n",
    "    print(p)\n",
    "\n",
    "\n",
    "update_working_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import src.data.get_dataset as get_dataset\n",
    "import src.data.make_dataset as make_dataset\n",
    "import src.data.make_predictions_next_session as make_predictions_next_session\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_path = \"data/raw/historical_data.csv\"\n",
    "vocab_path = \"data/raw/german_english.csv\"\n",
    "\n",
    "model_path = \"models/logistic_regression_mle__20201017__model.pkl\"\n",
    "\n",
    "dataset_predictions_path = \"data/raw/dataset_predictions.pkl\"\n",
    "probas_next_session_path = \"data/raw/predictions_next_session.csv\"\n",
    "\n",
    "make_predictions_next_session.make_predictions_next_session(\n",
    "    historical_data_path,\n",
    "    vocab_path,\n",
    "    model_path,\n",
    "    dataset_predictions_path,\n",
    "    probas_next_session_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_path = \"data/raw/20201017/historical_data.csv\"\n",
    "vocab_path = \"data/raw/20201017/german_english.csv\"\n",
    "\n",
    "dataset_predictions_path = \"data/raw/20201017/dataset_predictions.pkl\"\n",
    "probas_next_session_path = \"data/raw/20201017/predictions_next_session.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset_new_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dataset.create_dataset_new_session(\n",
    "    historical_data_path, vocab_path, dataset_predictions_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"models/logistic_regression_mle__20201017__model.pkl\", \"rb\") as input_file:\n",
    "    model = dill.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical data\n",
    "with open(dataset_predictions_path, \"rb\") as input_file:\n",
    "    dataset_predictions = dill.load(input_file)\n",
    "\n",
    "dataset_to_keep = dataset_predictions[\n",
    "    [\"id_vocab\", \"german_word\", \"english_word\", \"language_asked\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_predictions = model.preprocessing_inference(dataset_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dataset=dataset_predictions, target_present=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat([dataset_to_keep, predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_next_session = (\n",
    "    predictions[[\"id_vocab\", \"language_asked\", \"y_proba\"]]\n",
    "    .pivot(index=\"id_vocab\", columns=\"language_asked\", values=\"y_proba\")\n",
    "    .reset_index()\n",
    ")\n",
    "probas_next_session.columns.name = None\n",
    "\n",
    "probas_next_session.rename(\n",
    "    columns={\n",
    "        \"german\": \"german_proba\",\n",
    "        \"english\": \"english_proba\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "probas_next_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "probas_next_session.to_csv(probas_next_session_path, index=False)\n",
    "print(f\"Saved at {probas_next_session_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create traces\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=probas_next_session[\"german_proba\"],\n",
    "        name=\"german\",\n",
    "        xbins=dict(size=0.01)\n",
    "        # , histnorm='probability'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=probas_next_session[\"english_proba\"],\n",
    "        name=\"english\",\n",
    "        xbins=dict(size=0.01)\n",
    "        # , histnorm='probability'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"predictions\",\n",
    "    xaxis_title=\"prediction\",\n",
    "    yaxis_title=\"count\",\n",
    "    legend={\"itemsizing\": \"constant\"},\n",
    ")\n",
    "\n",
    "# fig.update_layout(barmode=\"overlay\")\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "vocabulary_learning",
   "language": "python",
   "name": "vocabulary_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

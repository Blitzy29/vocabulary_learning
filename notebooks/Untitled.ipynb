{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "* https://www.blendo.co/blog/recurrent-neural-networks-email-churn-prediction/\n",
    "* https://github.com/blendo-app/RNN_churn/blob/master/RNN_churn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Activation, Dense, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "import matplotlib.pylab as plt\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(data, n_prev = 4):\n",
    "    \"\"\"\n",
    "    Take every time n_prev elements of the dataframe, and the next element as the target\n",
    "    Here the rows seems to be the results.\n",
    "    So have the same size for each final array.\n",
    "    1st array: [row1, row2, row3, row4], [row5]\n",
    "    2nd array: [row2, row3, row4, row5], [row6]\n",
    "    etc ...\n",
    "    \"\"\"\n",
    "    \n",
    "    docX, docY = [], []\n",
    "    for i in range(len(data)-n_prev):\n",
    "        docX.append(data.iloc[i:i+n_prev].as_matrix())\n",
    "        docY.append(data.iloc[i+n_prev].as_matrix())\n",
    "    alsX = np.array(docX)\n",
    "    alsY = np.array(docY)\n",
    "\n",
    "    return alsX, alsY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size=0.1):\n",
    "    \"\"\" df is splitting by lines\n",
    "    \"\"\"\n",
    "\n",
    "    ntrn = round(len(df) * (1 - test_size))\n",
    "\n",
    "    X_train, y_train = _load_data(df.iloc[0:ntrn])\n",
    "    X_test, y_test = _load_data(df.iloc[ntrn:])\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_out_neurons = 1349 \n",
    "hidden_neurons = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(hidden_neurons, return_sequences=False,\n",
    "               input_shape=(None, in_out_neurons)))\n",
    "model.add(Dense(in_out_neurons, input_dim=hidden_neurons))  \n",
    "model.add(Activation(\"linear\"))  \n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\",  metrics=[metrics.binary_accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()  \n",
    "model2.add(LSTM(hidden_neurons, return_sequences=True, input_shape=(None, in_out_neurons)))  \n",
    "model2.add(LSTM(300, return_sequences=True))  \n",
    "model2.add(Dropout(0.2))  \n",
    "model2.add(LSTM(300, return_sequences=False))  \n",
    "model2.add(Dropout(0.2))  \n",
    "model2.add(Dense(in_out_neurons, input_dim=hidden_neurons))  \n",
    "model2.add(Activation(\"sigmoid\"))  \n",
    "model2.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[metrics.binary_accuracy])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __main__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PATH_TO_CSV_FILE', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate send_time to day\n",
    "df['send_time']=df['send_time'].values.astype('<M8[D]')\n",
    "df['actions']=df['opens']+df['clicks']\n",
    "del df['opens']\n",
    "del df['clicks']\n",
    "df.sort_values(by='send_time')\n",
    "\n",
    "# so we grouped all actions (open + click) and sort everything by time\n",
    "\n",
    "# group by email and send_time && pivot  \n",
    "df = df.groupby(['email_address','send_time'], as_index = False).sum(\n",
    ").pivot('email_address','send_time').fillna(0).transpose()\n",
    "\n",
    "# for each email and send_time, we sum all actions\n",
    "# and we pivot the table to have (after transpose)\n",
    "# rows: send_time (all of them)\n",
    "# cols: email_address\n",
    "# value: sum(action) = sum(open+click)\n",
    "# ! some values would have been empty -> we fill with 0\n",
    "\n",
    "# replace all non  zero counts with 1\n",
    "df[df != 0] = 1\n",
    "# so it is not a sum anymore, just a boolean\n",
    "\n",
    "# split is done by time (10% in test)\n",
    "# but data is multiplied: every sequence of 4 send_time is taken\n",
    "(X_train, y_train), (X_test, y_test) = train_test_split(data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each input of the data is a sequence of boolean (action/no-action) over a period of time. Here default is 4 points but I guess I can go larger.\n",
    "\n",
    "Padding for shorter time series: I can have a long list of NULL before the first element? Then same list.\n",
    "\n",
    "Or I can specify a length (5), padded all shorter ones and cut all longer ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=1, epochs=25)\n",
    "history2 = model2.fit(X_train, y_train, batch_size=1, epochs=20)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "predicted\n",
    "\n",
    "rmse = np.sqrt(((predicted - y_test) ** 2).mean(axis=0))\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.history['binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (13, 9)\n",
    "plt.plot(predicted[:100][:,0],\"--\")\n",
    "plt.plot(predicted[:100][:,1],\"--\")\n",
    "plt.plot(y_train[:100][:,0],\":\")\n",
    "plt.plot(y_train[:100][:,1],\":\")\n",
    "plt.legend([\"Prediction 0\", \"Prediction 1\", \"Test 0\", \"Test 1\"])  "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "vocabulary_learning__simple_rnn",
   "language": "python",
   "name": "vocabulary_learning__simple_rnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

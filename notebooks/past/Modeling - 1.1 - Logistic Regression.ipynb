{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "def update_working_directory():\n",
    "    from pathlib import Path\n",
    "\n",
    "    p = Path(os.getcwd()).parents[0]\n",
    "    os.chdir(p)\n",
    "    print(p)\n",
    "\n",
    "\n",
    "update_working_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset_train = \"data/raw/20201009/dataset_train.pkl\"\n",
    "path_dataset_valid = \"data/raw/20201009/dataset_valid.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from src.models.logistic_regression import ModelLogisticRegression\n",
    "import src.models.performance_metrics as performance_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_dataset_train, \"rb\") as input_file:\n",
    "    dataset_train = dill.load(input_file)\n",
    "\n",
    "with open(path_dataset_valid, \"rb\") as input_file:\n",
    "    dataset_valid = dill.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelLogisticRegression()\n",
    "\n",
    "model.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = model.preprocessing_training(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"models/{model.version}__model.pkl\", \"wb\") as file:\n",
    "    dill.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vardict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train[vardict[\"target\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train[vardict[\"numerical\"]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def data_transform_numerical(dataset, vardict):\n",
    "\n",
    "    dataset[\"previous_levenshtein_distance_guess_answer\"].fillna(-1, inplace=True)\n",
    "    dataset[\"previous_question_time\"].fillna(-1, inplace=True)\n",
    "    dataset[\"previous_write_it_again_german\"].fillna(-1, inplace=True)\n",
    "    dataset[\"previous_write_it_again_english\"].fillna(-1, inplace=True)\n",
    "\n",
    "    return dataset, vardict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Diff time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train[vardict[\"diff_time\"]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def data_transform_diff_time(dataset, vardict):\n",
    "\n",
    "    dataset[\"days_since_last_occurrence_same_language\"].fillna(-1, inplace=True)\n",
    "    dataset[\"days_since_last_occurrence_any_language\"].fillna(-1, inplace=True)\n",
    "    dataset[\"days_since_last_success_same_language\"].fillna(-1, inplace=True)\n",
    "    dataset[\"days_since_last_success_any_language\"].fillna(-1, inplace=True)\n",
    "    dataset[\"days_since_first_occur_same_language\"].fillna(-1, inplace=True)\n",
    "    dataset[\"days_since_first_occur_any_language\"].fillna(-1, inplace=True)\n",
    "\n",
    "    return dataset, vardict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train[vardict[\"boolean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def data_transform_boolean(dataset, vardict):\n",
    "\n",
    "    # Transform to dummies\n",
    "\n",
    "    vardict[\"dummy_boolean\"] = []\n",
    "\n",
    "    for i_var_boolean in vardict[\"boolean\"]:\n",
    "\n",
    "        # possible improvement: pandas.get_dummies(drop_first=False)\n",
    "        i_dummy_boolean = pd.get_dummies(\n",
    "            dataset[i_var_boolean],\n",
    "            prefix=i_var_boolean,\n",
    "            prefix_sep=\"__\",\n",
    "            dummy_na=True,\n",
    "        )\n",
    "\n",
    "        del dataset_train[i_var_boolean]\n",
    "\n",
    "        vardict[\"dummy_boolean\"] = (\n",
    "            vardict[\"dummy_boolean\"] + i_dummy_boolean.columns.tolist()\n",
    "        )\n",
    "\n",
    "        dataset = pd.concat([dataset, i_dummy_boolean], axis=1)\n",
    "\n",
    "    dataset[vardict[\"dummy_boolean\"]].describe()\n",
    "\n",
    "    return dataset, vardict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train[vardict[\"categorical\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def data_transform_categorical(dataset, vardict):\n",
    "\n",
    "    # Transform to dummies\n",
    "\n",
    "    vardict[\"dummy_categorical\"] = []\n",
    "\n",
    "    for i_var_categorical in vardict[\"categorical\"]:\n",
    "\n",
    "        # possible improvement: pandas.get_dummies(drop_first=False)\n",
    "        i_dummy_categorical = pd.get_dummies(\n",
    "            dataset[i_var_categorical],\n",
    "            prefix=i_var_categorical,\n",
    "            prefix_sep=\"__\",\n",
    "            dummy_na=True,\n",
    "        )\n",
    "\n",
    "        del dataset[i_var_categorical]\n",
    "\n",
    "        vardict[\"dummy_categorical\"] = (\n",
    "            vardict[\"dummy_categorical\"] + i_dummy_categorical.columns.tolist()\n",
    "        )\n",
    "\n",
    "        dataset = pd.concat([dataset, i_dummy_categorical], axis=1)\n",
    "\n",
    "    return dataset, vardict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train, vardict = data_transform_numerical(dataset_train, vardict)\n",
    "dataset_train, vardict = data_transform_diff_time(dataset_train, vardict)\n",
    "dataset_train, vardict = data_transform_boolean(dataset_train, vardict)\n",
    "dataset_train, vardict = data_transform_categorical(dataset_train, vardict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### vardict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vardict[\"all\"] = (\n",
    "    vardict[\"numerical\"]\n",
    "    + vardict[\"diff_time\"]\n",
    "    + vardict[\"dummy_boolean\"]\n",
    "    + vardict[\"dummy_categorical\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1st model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = dataset_train[vardict[\"all\"]]\n",
    "y_train = dataset_train[vardict[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(f\"data/processed/{model_name}_model.pkl\", \"wb\") as file:\n",
    "    dill.dump(model, file)\n",
    "\n",
    "with open(f\"data/processed/{model_name}_vardict.pkl\", \"wb\") as file:\n",
    "    dill.dump(vardict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_valid = model.preprocessing_inference(dataset_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dataset=dataset_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classification_results = performance_metrics.get_binary_classification_results(\n",
    "    predictions, model_name=f\"{model.version}_valid\"\n",
    ")\n",
    "\n",
    "binary_classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = performance_metrics.get_regression_results(\n",
    "    predictions, model_name=f\"{model.version}_valid\"\n",
    ")\n",
    "\n",
    "regression_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics.plot_roc_auc_curve(predictions, model_name=f\"{model.version}_valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics.plot_precision_recall_curve(\n",
    "    predictions, binary_classification_results, model_name=f\"{model.version}_valid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "vocabulary_learning",
   "language": "python",
   "name": "vocabulary_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

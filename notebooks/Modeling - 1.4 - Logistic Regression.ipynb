{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "def update_working_directory():\n",
    "    from pathlib import Path\n",
    "\n",
    "    p = Path(os.getcwd()).parents[0]\n",
    "    os.chdir(p)\n",
    "    print(p)\n",
    "\n",
    "\n",
    "update_working_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset_train = \"data/raw/20201009/dataset_train.pkl\"\n",
    "path_dataset_valid = \"data/raw/20201009/dataset_valid.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.models.logistic_regression import ModelLogisticRegression\n",
    "import src.models.performance_metrics as performance_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_dataset_train, \"rb\") as input_file:\n",
    "    dataset_train = dill.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelLogisticRegression()\n",
    "model.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = model.preprocessing_training(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"models/{model.version}__model.pkl\", \"wb\") as file:\n",
    "    dill.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vardict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train[model.vardict[\"target\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train[vardict[\"numerical\"]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def data_transform_numerical(dataset, vardict):\n",
    "\n",
    "    dataset[\"previous_levenshtein_distance_guess_answer\"].fillna(-1, inplace=True)\n",
    "    dataset[\"previous_question_time\"].fillna(-1, inplace=True)\n",
    "    dataset[\"previous_write_it_again_german\"].fillna(-1, inplace=True)\n",
    "    dataset[\"previous_write_it_again_english\"].fillna(-1, inplace=True)\n",
    "\n",
    "    return dataset, vardict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Diff time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train[vardict[\"diff_time\"]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def data_transform_diff_time(dataset, vardict):\n",
    "\n",
    "    dataset[\"days_since_last_occurrence_same_language\"].fillna(-1, inplace=True)\n",
    "    dataset[\"days_since_last_occurrence_any_language\"].fillna(-1, inplace=True)\n",
    "    dataset[\"days_since_last_success_same_language\"].fillna(-1, inplace=True)\n",
    "    dataset[\"days_since_last_success_any_language\"].fillna(-1, inplace=True)\n",
    "    dataset[\"days_since_first_occur_same_language\"].fillna(-1, inplace=True)\n",
    "    dataset[\"days_since_first_occur_any_language\"].fillna(-1, inplace=True)\n",
    "\n",
    "    return dataset, vardict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train[vardict[\"boolean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def data_transform_boolean(dataset, vardict):\n",
    "\n",
    "    # Transform to dummies\n",
    "\n",
    "    vardict[\"dummy_boolean\"] = []\n",
    "\n",
    "    for i_var_boolean in vardict[\"boolean\"]:\n",
    "\n",
    "        # possible improvement: pandas.get_dummies(drop_first=False)\n",
    "        i_dummy_boolean = pd.get_dummies(\n",
    "            dataset[i_var_boolean],\n",
    "            prefix=i_var_boolean,\n",
    "            prefix_sep=\"__\",\n",
    "            dummy_na=True,\n",
    "        )\n",
    "\n",
    "        del dataset_train[i_var_boolean]\n",
    "\n",
    "        vardict[\"dummy_boolean\"] = (\n",
    "            vardict[\"dummy_boolean\"] + i_dummy_boolean.columns.tolist()\n",
    "        )\n",
    "\n",
    "        dataset = pd.concat([dataset, i_dummy_boolean], axis=1)\n",
    "\n",
    "    dataset[vardict[\"dummy_boolean\"]].describe()\n",
    "\n",
    "    return dataset, vardict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train[model.vardict[\"categorical\"]][\"previous_language_asked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def data_transform_categorical(dataset, vardict):\n",
    "\n",
    "    # Transform to dummies\n",
    "\n",
    "    vardict[\"dummy_categorical\"] = []\n",
    "\n",
    "    for i_var_categorical in vardict[\"categorical\"]:\n",
    "\n",
    "        # possible improvement: pandas.get_dummies(drop_first=False)\n",
    "        i_dummy_categorical = pd.get_dummies(\n",
    "            dataset[i_var_categorical],\n",
    "            prefix=i_var_categorical,\n",
    "            prefix_sep=\"__\",\n",
    "            dummy_na=True,\n",
    "        )\n",
    "\n",
    "        del dataset[i_var_categorical]\n",
    "\n",
    "        vardict[\"dummy_categorical\"] = (\n",
    "            vardict[\"dummy_categorical\"] + i_dummy_categorical.columns.tolist()\n",
    "        )\n",
    "\n",
    "        dataset = pd.concat([dataset, i_dummy_categorical], axis=1)\n",
    "\n",
    "    return dataset, vardict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train, vardict = data_transform_numerical(dataset_train, vardict)\n",
    "dataset_train, vardict = data_transform_diff_time(dataset_train, vardict)\n",
    "dataset_train, vardict = data_transform_boolean(dataset_train, vardict)\n",
    "dataset_train, vardict = data_transform_categorical(dataset_train, vardict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### vardict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vardict[\"all\"] = (\n",
    "    vardict[\"numerical\"]\n",
    "    + vardict[\"diff_time\"]\n",
    "    + vardict[\"dummy_boolean\"]\n",
    "    + vardict[\"dummy_categorical\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1st model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = ModelLogisticRegression()\n",
    "model.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train = model.preprocessing_training(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = dataset[model.vardict[\"into_model\"]]\n",
    "y_train = dataset[model.vardict[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_Reg = LogisticRegression(solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[(\"logistic_Reg\", logistic_Reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "C = np.logspace(-4, 4, 50)\n",
    "penalty = [\"l1\", \"l2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parameters = dict(logistic_Reg__C=C, logistic_Reg__penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf_GS = GridSearchCV(pipe, parameters)\n",
    "clf_GS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Best Penalty:\", clf_GS.best_estimator_.get_params()[\"logistic_Reg__penalty\"])\n",
    "print(\"Best C:\", clf_GS.best_estimator_.get_params()[\"logistic_Reg__C\"])\n",
    "print()\n",
    "print(clf_GS.best_estimator_.get_params()[\"logistic_Reg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os = SMOTE(random_state=0)\n",
    "X_train = dataset[model.vardict[\"all\"]]\n",
    "y_train = dataset[[model.vardict[\"target\"]]]\n",
    "X_train_os, y_train_os_series = os.fit_sample(X_train, y_train)\n",
    "y_train_os = pd.DataFrame()\n",
    "y_train_os[model.vardict[\"target\"]] = y_train_os_series\n",
    "dataset = pd.concat([X_train_os, y_train_os], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train_os_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os = SMOTE(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_os, y_train_os = os.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_test2 = pd.concat([X_train_os, y_train_os], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(X_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os_data_X = pd.DataFrame(data=X_train_os, columns=X_train.columns)\n",
    "os_data_y = pd.DataFrame()\n",
    "os_data_y[\"y\"] = y_train_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \", len(os_data_X))\n",
    "print(\n",
    "    \"Number of no subscription in oversampled data\", len(os_data_y[os_data_y[\"y\"] == 0])\n",
    ")\n",
    "print(\"Number of subscription\", len(os_data_y[os_data_y[\"y\"] == 1]))\n",
    "print(\n",
    "    \"Proportion of no subscription data in oversampled data is \",\n",
    "    len(os_data_y[os_data_y[\"y\"] == 0]) / len(os_data_X),\n",
    ")\n",
    "print(\n",
    "    \"Proportion of subscription data in oversampled data is \",\n",
    "    len(os_data_y[os_data_y[\"y\"] == 1]) / len(os_data_X),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(f\"data/processed/{model_name}_model.pkl\", \"wb\") as file:\n",
    "    dill.dump(model, file)\n",
    "\n",
    "with open(f\"data/processed/{model_name}_vardict.pkl\", \"wb\") as file:\n",
    "    dill.dump(vardict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_dataset_valid, \"rb\") as input_file:\n",
    "    dataset_valid = dill.load(input_file)\n",
    "y_valid = dataset_valid[model.vardict[\"target\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_valid = model.preprocessing_inference(dataset_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dataset=dataset_valid, target_present=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"y_true\"] = y_valid.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classification_results = performance_metrics.get_binary_classification_results(\n",
    "    predictions, model_name=f\"{model.version}_valid\"\n",
    ")\n",
    "\n",
    "binary_classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = performance_metrics.get_regression_results(\n",
    "    predictions, model_name=f\"{model.version}_valid\"\n",
    ")\n",
    "\n",
    "regression_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics.plot_roc_auc_curve(predictions, model_name=f\"{model.version}_valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics.plot_precision_recall_curve(\n",
    "    predictions, binary_classification_results, model_name=f\"{model.version}_valid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics.plot_predictions(predictions, model_name=f\"{model.version}_valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(path_dataset_train, \"rb\") as input_file:\n",
    "    dataset_train = dill.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = ModelLogisticRegression()\n",
    "model.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "dimension_reduction = PCA()\n",
    "model_logistic_regression = LogisticRegression()\n",
    "feature_selection = RFE(estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1st part preprocessing - fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_train = model.preprocessing_training_numerical(dataset_train)\n",
    "dataset_train = model.preprocessing_training_diff_time(dataset_train)\n",
    "dataset_train = model.preprocessing_training_boolean(dataset_train)\n",
    "dataset_train = model.preprocessing_training_categorical(dataset_train)\n",
    "\n",
    "model.vardict[\"preprocessed\"] = (\n",
    "        model.vardict[\"numerical\"]\n",
    "        + model.vardict[\"diff_time\"]\n",
    "        + model.vardict[\"dummy_boolean\"]\n",
    "        + model.vardict[\"dummy_categorical\"]\n",
    ")\n",
    "\n",
    "# SMOTE\n",
    "# dataset_train = model.apply_sampling(dataset_train)\n",
    "\n",
    "\n",
    "X_train = dataset_train[model.vardict[\"preprocessed\"]]\n",
    "y_train = dataset_train[[model.vardict[\"target\"]]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"std_slc\", scaler),\n",
    "        (\"pca\", dimension_reduction),\n",
    "        (\"feat_select\", feature_selection),\n",
    "        (\"logistic_Reg\", model_logistic_regression),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"pca__n_components\": list(range(1, X_train.shape[1] + 1, 1)),\n",
    "    \"logistic_Reg__penalty\": [\"l1\", \"l2\"],\n",
    "    \"logistic_Reg__C\": np.logspace(-4, 4, 20),\n",
    "    \"logistic_Reg__solver\": [\"liblinear\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Create grid search object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pipe, param_grid=param_grid, cv=5, verbose=True, n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Fit on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"----- Best parameters -----\")\n",
    "for i_parameter in list(param_grid.keys()):\n",
    "    print(\"{} - {}\".format(i_parameter, clf.best_params_[i_parameter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hyperparameters_df = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "hyperparameters_df[\"rank_test_score_inverse\"] = (\n",
    "    max(hyperparameters_df[\"rank_test_score\"]) - hyperparameters_df[\"rank_test_score\"]\n",
    ")\n",
    "hyperparameters_df.sort_values(\"rank_test_score_inverse\", inplace=True)\n",
    "hyperparameters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i_parameter in list(param_grid.keys()):\n",
    "    # variable_to_plot = \"param_pca__n_components\"\n",
    "    variable_to_plot = f\"param_{i_parameter}\"\n",
    "\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # hyperparameters_df.sort_values(variable_to_plot, inplace=True)\n",
    "\n",
    "    # Create traces\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=hyperparameters_df[variable_to_plot],\n",
    "            y=hyperparameters_df[\"rank_test_score_inverse\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                color=hyperparameters_df[\"mean_test_score\"],\n",
    "                colorscale=\"Viridis_r\",  # one of plotly colorscales\n",
    "                colorbar=dict(title=\"mean_test_score\"),\n",
    "                showscale=True,\n",
    "            ),\n",
    "            hovertemplate=\"<b>Trial %{y}</b><br><br>\"\n",
    "            + \"Value: %{x:.5f}<br>\"\n",
    "            + \"MAE: %{marker.color:.3f}<br>\"\n",
    "            + \"<extra></extra>\",\n",
    "            showlegend=False,\n",
    "            name=variable_to_plot,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if i_parameter in [\"logistic_Reg__C\"]:\n",
    "        fig.update_xaxes(type=\"log\")\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[\n",
    "                clf.best_params_[i_parameter],\n",
    "                clf.best_params_[i_parameter],\n",
    "            ],\n",
    "            y=[\n",
    "                min(hyperparameters_df[\"rank_test_score_inverse\"]),\n",
    "                max(hyperparameters_df[\"rank_test_score_inverse\"]),\n",
    "            ],\n",
    "            mode=\"lines\",\n",
    "            showlegend=False,\n",
    "            line=dict(color=\"#e377c2\", dash=\"dash\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Evolution of hyperparameter {} by trial\".format(variable_to_plot),\n",
    "        xaxis_title=variable_to_plot,\n",
    "        yaxis_title=\"Rank number (the higher, the better ranked)\",\n",
    "        legend={\"itemsizing\": \"constant\"},\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        annotations=[\n",
    "            go.layout.Annotation(\n",
    "                text=\"Vertical line: best score\",\n",
    "                align=\"center\",\n",
    "                showarrow=False,\n",
    "                xref=\"paper\",\n",
    "                yref=\"paper\",\n",
    "                x=0.5,\n",
    "                y=-0.22,\n",
    "                bordercolor=\"black\",\n",
    "                borderwidth=1,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probas & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"models/{model.version}__model.pkl\", \"rb\") as input_file:\n",
    "    model = dill.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get historical data\n",
    "path_dataset = \"data/raw/20201009/dataset_predictions.pkl\"\n",
    "with open(path_dataset, \"rb\") as input_file:\n",
    "    dataset_predictions = dill.load(input_file)\n",
    "\n",
    "dataset_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = dataset_predictions[model.vardict[\"target\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_predictions = model.preprocessing_inference(dataset_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dataset=dataset_predictions, target_present=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"y_true\"] = y_true.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "vocabulary_learning",
   "language": "python",
   "name": "vocabulary_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
